{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ranking_Hierec_MIND_Large_20211.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from contextlib import redirect_stdout\n",
        "import os\n",
        "from zipfile import ZipFile, ZIP_DEFLATED\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_sort_order(input_score):\n",
        "    real_order = [0]*len(input_score)\n",
        "    tmp_order = np.argsort(input_score)[::-1]\n",
        "    for i in range(len(input_score)):\n",
        "      real_order[tmp_order[i]] = i+1\n",
        "    return real_order\n",
        "\n",
        "def get_data_from_path(path):\n",
        "    f = open(path,'r')\n",
        "    data_1 = json.load(f)\n",
        "    f.close()\n",
        "    return data_1\n",
        "\n",
        "\n",
        "def print_submissions(ranking_data,output_path=\"submissions.txt\"):\n",
        "  with open(output_path, 'w') as f:\n",
        "        with redirect_stdout(f):\n",
        "            for p in ranking_data:\n",
        "              tmp_score = p['ranked_score']\n",
        "              rank_str = '[' + ','.join([str(i) for i in tmp_score]) + ']'\n",
        "              print(p['imp_id'], rank_str)\n",
        "\n",
        "\n",
        "def write_to_zip(zip_name='prediction.zip'):\n",
        "  f = ZipFile(zip_name, 'w', ZIP_DEFLATED)\n",
        "  f.write('prediction.txt', arcname='prediction.txt')\n",
        "  f.close()\n",
        "\n",
        "def dump_json(test_data,output_json_name=None):\n",
        "    if output_json_name is not None:\n",
        "            with open(output_json_name, \"w\",encoding='utf8') as output_file:\n",
        "                json.dump(test_data,output_file,ensure_ascii=False)\n",
        "\n",
        "def to_lightweight_data(data):\n",
        "    new_data = []\n",
        "    for i in range(len(data)):\n",
        "        new_data.append({'imp_id':data[i]['imp_id'],\n",
        "                        'float_score':data[i]['float_score'],\n",
        "                        'ranked_score':data[i]['ranked_score'],\n",
        "                         'have_hist':data[i]['have_hist']})\n",
        "    return new_data"
      ],
      "metadata": {
        "id": "LDQcSFOKLiuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Contain paths to all evaluation files (sorted according to order in the original MIND Large Test)\n",
        "# data_paths = ['/content/drive/MyDrive/12_26_HieRec_Eval/12_27_default_ranking_data_portion_0_25.json',\n",
        "#               '/content/drive/MyDrive/12_26_HieRec_Eval/12_27_default_ranking_data_portion_25_50.json',\n",
        "#               '/content/drive/MyDrive/12_26_HieRec_Eval/12_27_default_ranking_data_portion_50_75.json',\n",
        "#               '/content/drive/MyDrive/12_26_HieRec_Eval/12_27_default_ranking_data_portion_75_100.json']\n",
        "\n",
        "# all_ranking = []\n",
        "# import os\n",
        "# for f in data_paths:\n",
        "#     all_ranking += get_data_from_path(f)"
      ],
      "metadata": {
        "id": "xfQ0anLhYCsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this script to get ranking submission\n",
        "print_submissions(ranking_data=all_ranking,\n",
        "                  output_path=\"prediction.txt\")\n",
        "write_to_zip('12_27_ranking.zip')"
      ],
      "metadata": {
        "id": "uQEHNbOF1u-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get news to count_occurences dictionary\n",
        "# # However, this methods yields low result on test set\n",
        "# test_occurence = get_data_from_path('/content/drive/MyDrive/HieRec_Json/news_to_occurence_dict.json')\n",
        "# print(test_occurence.items())"
      ],
      "metadata": {
        "id": "hWm_3vdOSzlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check format\n",
        "with open(\"prediction.txt\",'r') as f:\n",
        "  popu_list = f.readlines()\n",
        "print(popu_list[:3])"
      ],
      "metadata": {
        "id": "CwIyAupr0g0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}